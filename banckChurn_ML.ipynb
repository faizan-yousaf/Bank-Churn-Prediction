{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "# **Bank Churn Prediction using Machine Learning**:\n",
    "An efficient approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div >\n",
    "  <img src=\"https://res.cloudinary.com/dhditogyd/image/upload/v1738308892/Bank_Churn_ML_notebook_cover_xfnax4.png\" width=\"100%\" height=\" 100%;\"/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "\n",
    "Author: [Muhammad Faizan](https://www.linkedin.com/in/mrfaizanyousaf/)\n",
    "\n",
    "<div >\n",
    "  <img src=\"https://res.cloudinary.com/dhditogyd/image/upload/v1735402856/Passport_photo_jsvsip.png\" width=\"20%\" height=\" 20%;\"/>\n",
    "</div>\n",
    "\n",
    "**Muhammad Faizan**\n",
    "\n",
    "ðŸŽ“ **3rd Year BS Computer Science** student at the **University of Agriculture, Faisalabad**  \n",
    "ðŸ’» Enthusiast in **Machine Learning, Data Engineering, and Data Analytics**\n",
    "\n",
    "\n",
    "ðŸŒ **Connect with Me**\n",
    "\n",
    "[Kaggle](https://www.kaggle.com/faizanyousafonly/) | [LinkedIn](https://www.linkedin.com/in/mrfaizanyousaf/) | [GitHub](https://github.com/faizan-yousaf/)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ðŸ’¬ **Contact Me**\n",
    "- **Email:** faizanyousaf815@gmail.com\n",
    "- **WhatsApp:** [+92 306 537 5389](https://wa.me/923065375389)\n",
    "\n",
    "\n",
    "ðŸ”— **Letâ€™s Collaborate:**  \n",
    "I'm always open to queries, collaborations, and discussions. Let's build something amazing together!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Meta-Data (About Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Context: \n",
    "This dataset is designed to predict **customer churn** in the banking industry. It contains essential information about customers who either left the bank or continued to stay. Below is a breakdown of the dataset's attributes:\n",
    "\n",
    "### Content:\n",
    "ðŸ” Access the dataset:\n",
    "[Dataset_link](https://www.kaggle.com/competitions/playground-series-s4e1/data)\n",
    "\n",
    "#### Column Descriptions:\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| **ðŸ‘¤ Customer ID** | A unique identifier for each customer. |\n",
    "| **ðŸ”  Surname** | The customer's last name. |\n",
    "| **ðŸ“ˆ Credit Score** | A numerical value representing the customer's credit score. |\n",
    "| **ðŸŒ Geography** | The country where the customer resides (France, Spain, or Germany). |\n",
    "| **ðŸš» Gender** | The customer's gender (Male or Female). |\n",
    "| **ðŸŽ‚ Age** | The customer's age. |\n",
    "| **ðŸ“† Tenure** | The number of years the customer has been with the bank. |\n",
    "| **ðŸ’° Balance** | The customer's account balance. |\n",
    "| **ðŸ“¦ NumOfProducts** | The number of bank products the customer uses (e.g., savings account, credit card). |\n",
    "| **ðŸ’³ HasCrCard** | Whether the customer has a credit card (1 = yes, 0 = no). |\n",
    "| **âœ… IsActiveMember** | Whether the customer is an active member (1 = yes, 0 = no). |\n",
    "| **ðŸ’µ EstimatedSalary** | The estimated salary of the customer. |\n",
    "| **ðŸšª Exited** | Whether the customer has churned (1 = yes, 0 = no). |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Acknowledgements\n",
    "### Creators:\n",
    "\n",
    "* Authors = Walter Reade and Ashley Chow,\n",
    "\n",
    "\n",
    "\n",
    "### Citation Request:\n",
    "\n",
    "Walter Reade and Ashley Chow. Binary Classification with a Bank Churn Dataset . [Cited](https://kaggle.com/competitions/playground-series-s4e1), 2024. Kaggle.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Aims and Objectives:\n",
    "\n",
    "We will fill this after doing the EDA and Data Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "# ðŸ—ºï¸ **Project Roadmap: Whatâ€™s Happening in This Notebook?**  \n",
    "\n",
    "Welcome to my Machine Learning project notebook! Hereâ€™s a quick overview of what weâ€™ll be covering in this notebook. Iâ€™ve already completed some steps, and now weâ€™ll focus on the remaining tasks to prepare for Kaggle submission and GitHub sharing. Letâ€™s dive in!  \n",
    "\n",
    "\n",
    "## âœ… **1. Setting Up the Environment**  \n",
    "- **Whatâ€™s done:** All necessary libraries (`pandas`, `numpy`, `scikit-learn`, etc.) are imported, and the dataset is loaded.  \n",
    "- **Whatâ€™s next:** Weâ€™ll ensure everything is ready for the next steps.  \n",
    "\n",
    "\n",
    "## ðŸ“‰ **2. Exploratory Data Analysis (EDA)**  \n",
    "- **Whatâ€™s done:** Iâ€™ve already performed a detailed EDA in a separate notebook. You can check it out here: [My EDA Notebook]( https://www.kaggle.com/code/faizanyousafonly/customer-churn-secrets-an-eda-journey).  \n",
    "- **Whatâ€™s next:** Weâ€™ll briefly recap key insights from the EDA to set the stage for preprocessing.  \n",
    "\n",
    "\n",
    "## ðŸ› ï¸ **3. Data Preprocessing**  \n",
    "- **Whatâ€™s done:** Identified missing values, outliers, and feature relationships during EDA.  \n",
    "- **Whatâ€™s next:** Weâ€™ll handle missing values, encode categorical variables, and split the data into training and testing sets.  \n",
    "\n",
    "\n",
    "## ðŸ¤– **4. Model Building**  \n",
    "- **Whatâ€™s done:** Explored different algorithms during EDA to identify the best candidate.  \n",
    "- **Whatâ€™s next:** Weâ€™ll train the chosen model, tune hyperparameters, and evaluate its performance.  \n",
    "\n",
    "\n",
    "## ðŸ“Š **5. Model Evaluation**  \n",
    "- **Whatâ€™s done:** Defined evaluation metrics based on the problem type (classification/regression).  \n",
    "- **Whatâ€™s next:** Weâ€™ll generate predictions, create visualizations, and analyze the modelâ€™s performance.  \n",
    "\n",
    "\n",
    "## ðŸš€ **6. Preparing for Kaggle Submission**  \n",
    "- **Whatâ€™s done:** Understood Kaggleâ€™s submission format and requirements.  \n",
    "- **Whatâ€™s next:** Weâ€™ll save the model, format predictions, and create a submission CSV file for Kaggle.  \n",
    "\n",
    "\n",
    "## ðŸ“‚ **7. Uploading to GitHub**  \n",
    "- **Whatâ€™s done:** Organized project files and prepared documentation.  \n",
    "- **Whatâ€™s next:** Weâ€™ll upload the notebook, dataset, and submission files to GitHub and write a clear `README.md`.  \n",
    "\n",
    "\n",
    "## ðŸŒŸ **8. Sharing the Project**  \n",
    "- **Whatâ€™s done:** Prepared links for sharing on Kaggle and GitHub.  \n",
    "- **Whatâ€™s next:** Weâ€™ll share the project with the community and celebrate our hard work! ðŸŽ‰  \n",
    "\n",
    "---\n",
    "\n",
    "This notebook is the final step in my Machine Learning project journey. Letâ€™s get started! ðŸš€  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## âœ… **1. Setting Up the Environment** \n",
    "\n",
    "Let's start the project by importing all the libraries that we will use in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries have been loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# import libraries:\n",
    "\n",
    "# 1. to handel the data:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 2. to visualize the data:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# 3. to preprocess the data:\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 4. to build the model:\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# 5. for classification task:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 6. Metrics:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, r2_score, f1_score , classification_report, root_mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 7. to ignore the warnings:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries have been loaded successfully\")\n",
    "\n",
    "# # 8. Display all rows and columns: (uncomment if you want the whole output in the cells, I don't prefer it while uploading my notebook on Kaggle or Github)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a style for the plots\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1. ðŸ“Š Loading and Peeking at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset... ðŸ•µï¸â€â™‚ï¸\n",
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Step 1: Loading the Data\n",
    "print(\"Loading the dataset... ðŸ•µï¸â€â™‚ï¸\")\n",
    "df_train = pd.read_csv(\"../cleaned/train_preprocessed.csv\")\n",
    "df_test = pd.read_csv(\"../cleaned/test_preprocessed.csv\")\n",
    "submission = pd.read_csv(\"../dataset/sample_submission.csv\")\n",
    "print(\"Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "> Let's have a look on each dataset: ðŸ‘€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessed training dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>CreditScoreCategory</th>\n",
       "      <th>BalanceCategory</th>\n",
       "      <th>SalaryCategory</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15741417</td>\n",
       "      <td>Kao</td>\n",
       "      <td>581</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15766172</td>\n",
       "      <td>Chiemenam</td>\n",
       "      <td>716</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  CustomerId         Surname  CreditScore   Age  Tenure    Balance  \\\n",
       "0   0    15674932  Okwudilichukwu          668  33.0       3       0.00   \n",
       "1   1    15749177   Okwudiliolisa          627  33.0       1       0.00   \n",
       "2   2    15694510           Hsueh          678  40.0      10       0.00   \n",
       "3   3    15741417             Kao          581  34.0       2  148882.54   \n",
       "4   4    15766172       Chiemenam          716  33.0       5       0.00   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
       "0              2        1.0             0.0        181449.97       0   \n",
       "1              2        1.0             1.0         49503.50       0   \n",
       "2              2        1.0             0.0        184866.69       0   \n",
       "3              1        1.0             1.0         84560.88       0   \n",
       "4              2        1.0             1.0         15068.83       0   \n",
       "\n",
       "   AgeCategory  CreditScoreCategory  BalanceCategory  SalaryCategory  \\\n",
       "0            2                  1.0              3.0             5.0   \n",
       "1            2                  1.0              3.0             1.0   \n",
       "2            3                  2.0              3.0             5.0   \n",
       "3            2                  1.0              1.0             2.0   \n",
       "4            2                  2.0              3.0             6.0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Male  \n",
       "0                0.0              0.0          1.0  \n",
       "1                0.0              0.0          1.0  \n",
       "2                0.0              0.0          1.0  \n",
       "3                0.0              0.0          1.0  \n",
       "4                0.0              1.0          1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessed testing dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>CreditScoreCategory</th>\n",
       "      <th>BalanceCategory</th>\n",
       "      <th>SalaryCategory</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165034</td>\n",
       "      <td>15773898</td>\n",
       "      <td>Lucchese</td>\n",
       "      <td>586</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160976.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165035</td>\n",
       "      <td>15782418</td>\n",
       "      <td>Nott</td>\n",
       "      <td>683</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72549.27</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165036</td>\n",
       "      <td>15807120</td>\n",
       "      <td>K?</td>\n",
       "      <td>656</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138882.09</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165037</td>\n",
       "      <td>15808905</td>\n",
       "      <td>O'Donnell</td>\n",
       "      <td>681</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165038</td>\n",
       "      <td>15607314</td>\n",
       "      <td>Higgins</td>\n",
       "      <td>752</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10</td>\n",
       "      <td>121263.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139431.00</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  CustomerId    Surname  CreditScore   Age  Tenure    Balance  \\\n",
       "0  165034    15773898   Lucchese          586  23.0       2       0.00   \n",
       "1  165035    15782418       Nott          683  46.0       2       0.00   \n",
       "2  165036    15807120         K?          656  34.0       7       0.00   \n",
       "3  165037    15808905  O'Donnell          681  36.0       8       0.00   \n",
       "4  165038    15607314    Higgins          752  38.0      10  121263.62   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  AgeCategory  \\\n",
       "0              2        0.0             1.0        160976.75            2   \n",
       "1              1        1.0             0.0         72549.27            3   \n",
       "2              2        1.0             0.0        138882.09            2   \n",
       "3              1        1.0             0.0        113931.57            3   \n",
       "4              1        1.0             0.0        139431.00            3   \n",
       "\n",
       "   CreditScoreCategory  BalanceCategory  SalaryCategory  Geography_Germany  \\\n",
       "0                  1.0              3.0             0.0                0.0   \n",
       "1                  2.0              3.0             2.0                0.0   \n",
       "2                  1.0              3.0             4.0                0.0   \n",
       "3                  2.0              3.0             3.0                0.0   \n",
       "4                  3.0              1.0             4.0                1.0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0              0.0          0.0  \n",
       "1              0.0          0.0  \n",
       "2              0.0          0.0  \n",
       "3              0.0          1.0  \n",
       "4              0.0          1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165034</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165035</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165036</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165037</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165038</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  Exited\n",
       "0  165034     0.5\n",
       "1  165035     0.5\n",
       "2  165036     0.5\n",
       "3  165037     0.5\n",
       "4  165038     0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The preprocessed training dataset:\")\n",
    "display(df_train.head())\n",
    "\n",
    "print(\"The preprocessed testing dataset:\")\n",
    "display(df_test.head())\n",
    "\n",
    "print(\"The submission dataset:\")\n",
    "display(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset: (165034, 19)\n",
      "The shape of the testing dataset: (110023, 18)\n",
      "The shape of the submission dataset: (110023, 2)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of each:\n",
    "\n",
    "print(f\"The shape of the training dataset: {df_train.shape}\")\n",
    "\n",
    "print(f\"The shape of the testing dataset: {df_test.shape}\")\n",
    "\n",
    "print(f\"The shape of the submission dataset: {submission.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of the training dataset:\n",
      "1. id\n",
      "2. CustomerId\n",
      "3. Surname\n",
      "4. CreditScore\n",
      "5. Age\n",
      "6. Tenure\n",
      "7. Balance\n",
      "8. NumOfProducts\n",
      "9. HasCrCard\n",
      "10. IsActiveMember\n",
      "11. EstimatedSalary\n",
      "12. Exited\n",
      "13. AgeCategory\n",
      "14. CreditScoreCategory\n",
      "15. BalanceCategory\n",
      "16. SalaryCategory\n",
      "17. Geography_Germany\n",
      "18. Geography_Spain\n",
      "19. Gender_Male\n",
      "\n",
      "\n",
      "The columns of the testing dataset:\n",
      "1. id\n",
      "2. CustomerId\n",
      "3. Surname\n",
      "4. CreditScore\n",
      "5. Age\n",
      "6. Tenure\n",
      "7. Balance\n",
      "8. NumOfProducts\n",
      "9. HasCrCard\n",
      "10. IsActiveMember\n",
      "11. EstimatedSalary\n",
      "12. AgeCategory\n",
      "13. CreditScoreCategory\n",
      "14. BalanceCategory\n",
      "15. SalaryCategory\n",
      "16. Geography_Germany\n",
      "17. Geography_Spain\n",
      "18. Gender_Male\n",
      "\n",
      "\n",
      "The columns of the submission dataset:\n",
      "1. id\n",
      "2. Exited\n"
     ]
    }
   ],
   "source": [
    "# check the columns of each and print them in a presentable form:\n",
    "\n",
    "print(\"The columns of the training dataset:\")\n",
    "\n",
    "for i, col in enumerate(df_train.columns):\n",
    "    print(f\"{i+1}. {col}\")\n",
    "\n",
    "print(\"\\n\\nThe columns of the testing dataset:\")\n",
    "for i, col in enumerate(df_test.columns):\n",
    "    print(f\"{i+1}. {col}\")\n",
    "\n",
    "print(\"\\n\\nThe columns of the submission dataset:\")\n",
    "for i, col in enumerate(submission.columns):\n",
    "    print(f\"{i+1}. {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‰ **2. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "Iâ€™ve already performed a detailed EDA in a separate notebook. You can check it out here: [My EDA Notebook]( https://www.kaggle.com/code/faizanyousafonly/customer-churn-secrets-an-eda-journey).\n",
    "\n",
    "Weâ€™ll briefly recap key insights from the EDA to set the stage for preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Observations RECAP**: ðŸ”Ž\n",
    "\n",
    ">Data Overview ðŸ—‚ï¸\n",
    "\n",
    "1. **Data Types** ðŸ§¬:\n",
    "    * The dataset includes a mix of numerical (`int64`, `float64`) and categorical (`object`) data types. \n",
    "2.  Key columns:\n",
    "    * `CustomerId` (int64)\n",
    "    * `Surname` (object)\n",
    "    * `CreditScore` (int64)\n",
    "    * `Geography`, `Gender` (object)\n",
    "    * `Age`, `Tenure`, `Balance`, `NumOfProducts`, `EstimatedSalary` (float64)\n",
    "    * `HasCrCard`, `IsActiveMember`, `Exited` (int64)\n",
    "\n",
    "3. **Missing Values** ðŸš¨:\n",
    "    * No missing values detected in the dataset. This ensures the dataset is complete and ready for analysis without any need for imputation or handling missing data.\n",
    "\n",
    "4.  **Duplicate Values** ðŸ§©:\n",
    "    * The dataset does not contain any duplicate records. Each entry represents a unique customer, ensuring the integrity of the analysis.\n",
    "\n",
    "\n",
    "5. There are `165034` observations in the dataset.\n",
    "\n",
    "6. **Age Column:** ðŸŽ‚\n",
    "    * The average age of the individuals is 38 years which shows that most of the individuals are young adults.\n",
    "    * The mininum age is `18 years`. (a teenager)\n",
    "    * The maximum age is `92 years`. (an old man)\n",
    "\n",
    "7. **CustomerID:** ðŸ†”\n",
    "    * There were more than `fifteen million and five hundred` records from where the dataset is taken (quite astonishing right? ðŸ‘€)  \n",
    "    * The minimum ID count in our dataset is `15565701`\n",
    "    * The maximum ID count in our dataset is `15815690`\n",
    "\n",
    "8. **CreditScore:** ðŸ’¹\n",
    "    * The minimum credit score among the customer is : `350`\n",
    "    * The maximum credit score among the customer is: `850`\n",
    "\n",
    "9. **Tenure:** ðŸ“…\n",
    "    * The minimum time a customer was using our bank : `0 years`\n",
    "    * The maximum time a customer was using our bank : `10 years`\n",
    "\n",
    "10. **Balance:** ðŸ’°\n",
    "    * The minimum balance of a customer : `0.0` (That's probly ME... ðŸ˜‚)\n",
    "    * The maximum balance of a customer : `250898.09`\n",
    "    * The median is also : 0.0 (which is kinda curious... why many of the people have `Zero balance`ðŸ¤”)\n",
    "      * Either they don't use their bank account anymore\n",
    "      * Or They might don't trust this bank (that's a possibility)\n",
    "\n",
    "11. **NumOfProducts:** ðŸ“¦\n",
    "    * The minimum number of bank products any customer has: `1`\n",
    "    * The maximum number of bank products any customer has: `4`\n",
    "\n",
    "12. **HasCrCard:** ðŸ’³\n",
    "    * There are `124428` customers who have a credit card. (most of the customers have a credit card)\n",
    "    * **`75.4%`** percent customers have a credit card.\n",
    "    * There are `40606` customers who don't have a credit card. \n",
    "    * **`24.6%`** percent customers don't have a credit card.  \n",
    "\n",
    "13. **IsActiveMember:** âœŒðŸ»\n",
    "    *  Inactive users:  `82885`  with a percentage of **`50.2`**\n",
    "    *  Active users: `82149` with a percentage of **`49.8`**\n",
    "       * >NOTE: It shows that half of the whole customers are inactive means they don't use the bank at all... That's the reason why we had so many accounts with `Zero Balance` because these people don't use their accounts...\n",
    "\n",
    "14. **EstimatedSalary:** ðŸ’µ\n",
    "    * The minimum salary is : '11.58' \n",
    "    * The maximum salary is: '199992.48'\n",
    "\n",
    "15. **Exited** ðŸšª\n",
    "    * There are `34921` customers who churn the bank (`21.2 %`)\n",
    "    * There are `130113` customers who stayed in the bank (`78.8%`)\n",
    "  \n",
    ">Groupby Analysis ðŸ”\n",
    "\n",
    "1.  **Geography vs. Churn** ðŸŒðŸšª  \n",
    "  - Customers from **Germany** have the highest churn rate.  \n",
    "  - Customers from **France** show the lowest churn rate.\n",
    "\n",
    "2.  **Gender vs. Churn** ðŸ‘¥ðŸšª  \n",
    "  - **Female** customers tend to churn more often than **male** customers.\n",
    "\n",
    "3.  **Age vs. Churn** ðŸŽ‚ðŸšª  \n",
    "  - Customers aged **50 and above** are significantly more likely to leave.\n",
    "\n",
    "4.  **Tenure vs. Churn** ðŸ“…ðŸšª  \n",
    "  - Customers with a tenure of **1-2 years** are more prone to churn.  \n",
    "  - Those with **9-10 years** tenure are less likely to exit.\n",
    "\n",
    "5.  **Balance vs. Churn** ðŸ’°ðŸšª  \n",
    "  - Customers with a **zero balance** have a higher likelihood of exiting.\n",
    "\n",
    "6.  **Number of Products vs. Churn** ðŸ›’ðŸšª  \n",
    "  - Customers holding **only one product** are more likely to churn.  \n",
    "  - Those with **multiple products** show better retention.\n",
    "\n",
    "7.  **IsActiveMember vs. Churn** ðŸŸ¢ðŸšª  \n",
    "  - **Inactive members** have a substantially higher churn rate compared to active ones.  \n",
    "\n",
    "> Feature Engineering ðŸ”§\n",
    "\n",
    "- **Categorical Encoding** ðŸ—‚ï¸:\n",
    "  - Converted `Geography` and `Gender` into numerical features using one-hot encoding. This process ensures that categorical variables are appropriately represented in the model, with no redundant categories due to the `drop_first=True` option.\n",
    "\n",
    "- **AgeGroup Feature** ðŸŽ‚:\n",
    "  - Created the `AgeGroup` feature by binning `Age` into categories [0, 12, 19, 35, 50, 100]. This categorization can help in analyzing trends and patterns across different age groups.\n",
    "\n",
    "- **BalanceCategory Feature** ðŸ’µ:\n",
    "  - Created the `BalanceCategory` feature by binning `Balance` into categories ['No Balance', '0-100K', '100K-200K', '200K-300K', '300K-400K', '400K-500K', '500K-600K', '600K-700K', '700K-800K', '800K-900K', '900K-1M'].\n",
    "  - This categorization highlights how different balance levels affect customer churn.\n",
    "\n",
    "- **Feature Scaling** ðŸ“ˆ:\n",
    "  - I've `not scaled` the features as I've already make new features out of the original ones and then I encoded them, so they don't need to be scaled!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Observations ðŸ”  \n",
    "\n",
    "- âœ… **Data Integrity:** No missing or duplicate values, ensuring a solid foundation for analysis.  \n",
    "- ðŸ“Š **Feature Variability:** High standard deviations in `Balance` and `EstimatedSalary` suggest further investigation is needed.  \n",
    "- ðŸŒ **Churn Influences:** Factors like geography, gender, age, and engagement level (active vs inactive) impact customer churn.  \n",
    "- ðŸš€ **Feature Engineering Boost:** Newly introduced and scaled features enhance model performance and predictive accuracy.  \n",
    "- ðŸ”„ **Standardization Benefits:** Transformed features ensure better alignment for modeling, improving insights and decision-making.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ **3. Data Preprocessing**  \n",
    "- **Whatâ€™s done:** Identified missing values, outliers, and feature relationships during EDA.  \n",
    "- **Whatâ€™s next:** Weâ€™ll handle missing values, encode categorical variables, and split the data into training and testing sets.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Already done the preprocessing in the previous notebook, but let's just check out missing values once again to have confirmation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The missing values in the training dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "CustomerId             0\n",
       "Surname                0\n",
       "CreditScore            0\n",
       "Age                    0\n",
       "Tenure                 0\n",
       "Balance                0\n",
       "NumOfProducts          0\n",
       "HasCrCard              0\n",
       "IsActiveMember         0\n",
       "EstimatedSalary        0\n",
       "Exited                 0\n",
       "AgeCategory            0\n",
       "CreditScoreCategory    0\n",
       "BalanceCategory        0\n",
       "SalaryCategory         0\n",
       "Geography_Germany      0\n",
       "Geography_Spain        0\n",
       "Gender_Male            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------\n",
      "The missing values in the testing dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "CustomerId             0\n",
       "Surname                0\n",
       "CreditScore            0\n",
       "Age                    0\n",
       "Tenure                 0\n",
       "Balance                0\n",
       "NumOfProducts          0\n",
       "HasCrCard              0\n",
       "IsActiveMember         0\n",
       "EstimatedSalary        0\n",
       "AgeCategory            0\n",
       "CreditScoreCategory    0\n",
       "BalanceCategory        0\n",
       "SalaryCategory         0\n",
       "Geography_Germany      0\n",
       "Geography_Spain        0\n",
       "Gender_Male            0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the missing values in each dataset:\n",
    "\n",
    "print(\"The missing values in the training dataset:\")\n",
    "display(df_train.isnull().sum())\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "print(\"The missing values in the testing dataset:\")\n",
    "display(df_test.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No missing values in both datasets... `Confirmed`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– **4. Model Building**  \n",
    "- **Whatâ€™s done:** Explored different algorithms during EDA to identify the best candidate.  \n",
    "- **Whatâ€™s next:** Weâ€™ll train the chosen model, tune hyperparameters, and evaluate its performance.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'CustomerId', 'Surname', 'CreditScore', 'Age', 'Tenure',\n",
       "       'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
       "       'EstimatedSalary', 'Exited', 'AgeCategory', 'CreditScoreCategory',\n",
       "       'BalanceCategory', 'SalaryCategory', 'Geography_Germany',\n",
       "       'Geography_Spain', 'Gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the following columns as we have already transformed and encoded them. \n",
    "# Also, we will remove the target column from the training dataset.\n",
    "# the columns to be removed are: 'id, CustomerId', Surname, 'CreditScore', 'Geography', 'Age', 'Balance', 'EstimatedSalary', 'Exited'\n",
    "\n",
    "\n",
    "# drop the columns from the training dataset:\n",
    "\n",
    "df_train.drop(['id', 'CustomerId', 'Surname', 'CreditScore', 'Geography', 'Age', 'Balance', 'EstimatedSalary', 'Exited'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "\n",
    "X = df_train.drop('id','CustomerId', 'Surname', 'CreditScore', 'Age', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited', axis=1)\n",
    "y = df_train['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"The shape of the training set: {X_train.shape} and the shape of the testing set: {X_test.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
